{
 "display_name": "pySpark",
 "language": "python",
 "argv": [
  "/usr/bin/python2",
  "-m",
  "ipykernel",
  "-f",
  "{connection_file}"
 ],
 "env": {
  "SPARK_HOME": "/usr/hdp/current/spark-client",
  "HADOOP_CONF_DIR": "/etc/hadoop/conf",
  "PYTHONPATH": "/usr/hdp/current/spark-client/python/:/usr/hdp/current/spark-client/python/lib/py4j-0.9-src.zip",
  "PYTHONSTARTUP": "/usr/hdp/current/spark-client/python/pyspark/shell.py",
  "PYSPARK_SUBMIT_ARGS": "--master yarn-client --conf spark.serializer=org.apache.spark.serializer.KryoSerializer --conf spark.io.compression.codec=lzf --conf spark.speculation=true --conf spark.shuffle.manager=sort --conf spark.shuffle.service.enabled=true --conf spark.dynamicAllocation.enabled=true --conf spark.dynamicAllocation.initialExecutors=1 --conf spark.dynamicAllocation.minExecutors=1 --conf spark.executor.cores=1 --conf spark.executor.memory=512m pyspark-shell"
 }
}
